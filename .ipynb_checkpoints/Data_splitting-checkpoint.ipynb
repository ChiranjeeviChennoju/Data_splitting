{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02812ce",
   "metadata": {},
   "source": [
    "## Why Data Splitting Matters\n",
    "\n",
    "In supervised machine learning, the goal is to build a model that learns how to correctly connect inputs to outputs. The inputs are often called **features** or **predictors**, while the outputs are known as **targets** or **responses**.\n",
    "\n",
    "How well a model performs depends on the type of problem you’re solving.  \n",
    "- For **regression** tasks, performance is usually measured using metrics like **R²**, **root mean square error (RMSE)**, or **mean absolute error (MAE)**.  \n",
    "- For **classification** problems, common metrics include **accuracy**, **precision**, **recall**, and the **F1 score**.\n",
    "\n",
    "There’s no single *perfect* value for these metrics—what’s considered good performance can vary widely depending on the industry or use case. While many resources explain these metrics in detail, the most important thing to remember is this:\n",
    "\n",
    "> **A model must be evaluated fairly to be trusted.**\n",
    "\n",
    "You can’t accurately judge a model’s performance using the same data it was trained on, because the model has already *seen* that data. This would result in overly optimistic performance scores. Instead, the model should be tested on **new, unseen data** to understand how well it will perform in real-world situations.\n",
    "\n",
    "That’s why we split our dataset before training. One part is used to **train** the model, and another part is kept aside to **test** it. This separation ensures that performance metrics reflect the model’s true predictive ability, not just its ability to memorize the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582649f8",
   "metadata": {},
   "source": [
    "## Training, Validation, and Test Sets\n",
    "\n",
    "Splitting your dataset is a key step in making sure your model’s performance is evaluated fairly and realistically. In most machine learning projects, the dataset is randomly divided into **three parts**:\n",
    "\n",
    "### Training Set\n",
    "The **training set** is used to teach the model. This is where the model learns patterns in the data by adjusting its internal parameters.  \n",
    "For example, during training, a model learns the best weights or coefficients in algorithms like **linear regression**, **logistic regression**, or **neural networks**.\n",
    "\n",
    "### Validation Set\n",
    "The **validation set** is used to evaluate the model while you are fine-tuning it. This is especially useful during **hyperparameter tuning**.  \n",
    "For instance, if you’re deciding how many neurons to use in a neural network or which kernel works best for a support vector machine, you try different options. For each option, the model is trained on the training set and evaluated using the validation set to see which configuration performs best.\n",
    "\n",
    "### Test Set\n",
    "The **test set** is reserved for the final evaluation of the model. It provides an unbiased measure of how well the model performs on completely new data.  \n",
    "This dataset should **not** be used during training or validation, as doing so would compromise the fairness of the evaluation.\n",
    "\n",
    "In simpler scenarios—where hyperparameter tuning isn’t needed—it’s often acceptable to work with just **training** and **test** sets.\n",
    "\n",
    "---\n",
    "\n",
    "## Underfitting and Overfitting\n",
    "\n",
    "Splitting data also helps identify two common modeling problems: **underfitting** and **overfitting**.\n",
    "\n",
    "### Underfitting\n",
    "**Underfitting** occurs when a model is too simple to capture the underlying patterns in the data.  \n",
    "For example, using a linear model to describe a clearly nonlinear relationship can lead to underfitting. These models usually perform poorly on both the training and test datasets because they fail to learn meaningful patterns.\n",
    "\n",
    "### Overfitting\n",
    "**Overfitting** happens when a model is too complex and learns not only the true patterns in the data but also the noise.  \n",
    "Such models often perform extremely well on the training data but fail to generalize to new, unseen data. As a result, their performance on the test set is usually much worse.\n",
    "\n",
    "---\n",
    "\n",
    "Splitting your dataset properly helps you balance learning and generalization, ensuring that your model performs well not just on known data, but also in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412c6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    RepeatedKFold,\n",
    "    LeaveOneOut,\n",
    "    ShuffleSplit,\n",
    "    StratifiedShuffleSplit,\n",
    "    TimeSeriesSplit,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold,\n",
    "    PredefinedSplit,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c6faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('student_performance_updated_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df01b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "449430e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   StudentID                  960 non-null    float64\n",
      " 1   Name                       966 non-null    object \n",
      " 2   Gender                     952 non-null    object \n",
      " 3   AttendanceRate             960 non-null    float64\n",
      " 4   StudyHoursPerWeek          950 non-null    float64\n",
      " 5   PreviousGrade              967 non-null    float64\n",
      " 6   ExtracurricularActivities  957 non-null    float64\n",
      " 7   ParentalSupport            978 non-null    object \n",
      " 8   FinalGrade                 960 non-null    float64\n",
      " 9   Study Hours                976 non-null    float64\n",
      " 10  Attendance (%)             959 non-null    float64\n",
      " 11  Online Classes Taken       975 non-null    object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 93.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8403acbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AttendanceRate</th>\n",
       "      <th>StudyHoursPerWeek</th>\n",
       "      <th>PreviousGrade</th>\n",
       "      <th>ExtracurricularActivities</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>FinalGrade</th>\n",
       "      <th>Study Hours</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Online Classes Taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>John</td>\n",
       "      <td>Male</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Female</td>\n",
       "      <td>90.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Male</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Male</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>96.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Emma</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID     Name  Gender  AttendanceRate  StudyHoursPerWeek  \\\n",
       "0        1.0     John    Male            85.0               15.0   \n",
       "1        2.0    Sarah  Female            90.0               20.0   \n",
       "2        3.0     Alex    Male            78.0               10.0   \n",
       "3        4.0  Michael    Male            92.0               25.0   \n",
       "4        5.0     Emma  Female             NaN               18.0   \n",
       "\n",
       "   PreviousGrade  ExtracurricularActivities ParentalSupport  FinalGrade  \\\n",
       "0           78.0                        1.0            High        80.0   \n",
       "1           85.0                        2.0          Medium        87.0   \n",
       "2           65.0                        0.0             Low        68.0   \n",
       "3           90.0                        3.0            High        92.0   \n",
       "4           82.0                        2.0          Medium        85.0   \n",
       "\n",
       "   Study Hours  Attendance (%) Online Classes Taken  \n",
       "0          4.8            59.0                False  \n",
       "1          2.2            70.0                 True  \n",
       "2          4.6            92.0                False  \n",
       "3          2.9            96.0                False  \n",
       "4          4.1            97.0                 True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323d612d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentID                    40\n",
       "Name                         34\n",
       "Gender                       48\n",
       "AttendanceRate               40\n",
       "StudyHoursPerWeek            50\n",
       "PreviousGrade                33\n",
       "ExtracurricularActivities    43\n",
       "ParentalSupport              22\n",
       "FinalGrade                   40\n",
       "Study Hours                  24\n",
       "Attendance (%)               41\n",
       "Online Classes Taken         25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da648e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "\n",
    "# Create binary target: Pass (1) if FinalGrade >= 70, else Fail (0)\n",
    "df_clean = df.dropna(subset=['FinalGrade'])\n",
    "df_clean['Pass'] = (df_clean['FinalGrade'] >= 70).astype(int)\n",
    "\n",
    "# Select features\n",
    "feature_cols = ['AttendanceRate', 'StudyHoursPerWeek', 'PreviousGrade', \n",
    "                'ExtracurricularActivities', 'Study Hours', 'Attendance (%)']\n",
    "\n",
    "# Clean data\n",
    "df_clean = df_clean.dropna(subset=feature_cols)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[feature_cols].values\n",
    "y = df_clean['Pass'].values\n",
    "\n",
    "# Add Gender encoding\n",
    "if 'Gender' in df_clean.columns:\n",
    "    le = LabelEncoder()\n",
    "    gender_encoded = le.fit_transform(df_clean['Gender'].fillna('Unknown'))\n",
    "    X = np.column_stack([X, gender_encoded])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cb4ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (767, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bad53461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: (767,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282a6971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "  Pass (1): 615 samples (80.18%)\n",
      "  Fail (0): 152 samples (19.82%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class Distribution:\")\n",
    "print(f\"  Pass (1): {sum(y)} samples ({sum(y)/len(y)*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {len(y)-sum(y)} samples ({(len(y)-sum(y))/len(y)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb70ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
