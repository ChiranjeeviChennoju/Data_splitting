{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897ff958",
   "metadata": {},
   "source": [
    "## Why Data Splitting Matters\n",
    "\n",
    "In supervised machine learning, the goal is to build a model that learns how to correctly connect inputs to outputs. The inputs are often called **features** or **predictors**, while the outputs are known as **targets** or **responses**.\n",
    "\n",
    "How well a model performs depends on the type of problem youâ€™re solving.  \n",
    "- For **regression** tasks, performance is usually measured using metrics like **RÂ²**, **root mean square error (RMSE)**, or **mean absolute error (MAE)**.  \n",
    "- For **classification** problems, common metrics include **accuracy**, **precision**, **recall**, and the **F1 score**.\n",
    "\n",
    "Thereâ€™s no single *perfect* value for these metricsâ€”whatâ€™s considered good performance can vary widely depending on the industry or use case. While many resources explain these metrics in detail, the most important thing to remember is this:\n",
    "\n",
    "> **A model must be evaluated fairly to be trusted.**\n",
    "\n",
    "You canâ€™t accurately judge a modelâ€™s performance using the same data it was trained on, because the model has already *seen* that data. This would result in overly optimistic performance scores. Instead, the model should be tested on **new, unseen data** to understand how well it will perform in real-world situations.\n",
    "\n",
    "Thatâ€™s why we split our dataset before training. One part is used to **train** the model, and another part is kept aside to **test** it. This separation ensures that performance metrics reflect the modelâ€™s true predictive ability, not just its ability to memorize the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20725df",
   "metadata": {},
   "source": [
    "## Training, Validation, and Test Sets\n",
    "\n",
    "Splitting your dataset is a key step in making sure your modelâ€™s performance is evaluated fairly and realistically. In most machine learning projects, the dataset is randomly divided into **three parts**:\n",
    "\n",
    "### Training Set\n",
    "The **training set** is used to teach the model. This is where the model learns patterns in the data by adjusting its internal parameters.  \n",
    "For example, during training, a model learns the best weights or coefficients in algorithms like **linear regression**, **logistic regression**, or **neural networks**.\n",
    "\n",
    "### Validation Set\n",
    "The **validation set** is used to evaluate the model while you are fine-tuning it. This is especially useful during **hyperparameter tuning**.  \n",
    "For instance, if youâ€™re deciding how many neurons to use in a neural network or which kernel works best for a support vector machine, you try different options. For each option, the model is trained on the training set and evaluated using the validation set to see which configuration performs best.\n",
    "\n",
    "### Test Set\n",
    "The **test set** is reserved for the final evaluation of the model. It provides an unbiased measure of how well the model performs on completely new data.  \n",
    "This dataset should **not** be used during training or validation, as doing so would compromise the fairness of the evaluation.\n",
    "\n",
    "In simpler scenariosâ€”where hyperparameter tuning isnâ€™t neededâ€”itâ€™s often acceptable to work with just **training** and **test** sets.\n",
    "\n",
    "---\n",
    "\n",
    "## Underfitting and Overfitting\n",
    "\n",
    "Splitting data also helps identify two common modeling problems: **underfitting** and **overfitting**.\n",
    "\n",
    "### Underfitting\n",
    "**Underfitting** occurs when a model is too simple to capture the underlying patterns in the data.  \n",
    "For example, using a linear model to describe a clearly nonlinear relationship can lead to underfitting. These models usually perform poorly on both the training and test datasets because they fail to learn meaningful patterns.\n",
    "\n",
    "### Overfitting\n",
    "**Overfitting** happens when a model is too complex and learns not only the true patterns in the data but also the noise.  \n",
    "Such models often perform extremely well on the training data but fail to generalize to new, unseen data. As a result, their performance on the test set is usually much worse.\n",
    "\n",
    "---\n",
    "\n",
    "Splitting your dataset properly helps you balance learning and generalization, ensuring that your model performs well not just on known data, but also in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635be738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    RepeatedKFold,\n",
    "    LeaveOneOut,\n",
    "    ShuffleSplit,\n",
    "    StratifiedShuffleSplit,\n",
    "    TimeSeriesSplit,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold,\n",
    "    PredefinedSplit,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eeb2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('student_performance_updated_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10cdd9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1d1c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   StudentID                  960 non-null    float64\n",
      " 1   Name                       966 non-null    object \n",
      " 2   Gender                     952 non-null    object \n",
      " 3   AttendanceRate             960 non-null    float64\n",
      " 4   StudyHoursPerWeek          950 non-null    float64\n",
      " 5   PreviousGrade              967 non-null    float64\n",
      " 6   ExtracurricularActivities  957 non-null    float64\n",
      " 7   ParentalSupport            978 non-null    object \n",
      " 8   FinalGrade                 960 non-null    float64\n",
      " 9   Study Hours                976 non-null    float64\n",
      " 10  Attendance (%)             959 non-null    float64\n",
      " 11  Online Classes Taken       975 non-null    object \n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 93.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b51acce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AttendanceRate</th>\n",
       "      <th>StudyHoursPerWeek</th>\n",
       "      <th>PreviousGrade</th>\n",
       "      <th>ExtracurricularActivities</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>FinalGrade</th>\n",
       "      <th>Study Hours</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Online Classes Taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>John</td>\n",
       "      <td>Male</td>\n",
       "      <td>85.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Female</td>\n",
       "      <td>90.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Male</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Male</td>\n",
       "      <td>92.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>96.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Emma</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID     Name  Gender  AttendanceRate  StudyHoursPerWeek  \\\n",
       "0        1.0     John    Male            85.0               15.0   \n",
       "1        2.0    Sarah  Female            90.0               20.0   \n",
       "2        3.0     Alex    Male            78.0               10.0   \n",
       "3        4.0  Michael    Male            92.0               25.0   \n",
       "4        5.0     Emma  Female             NaN               18.0   \n",
       "\n",
       "   PreviousGrade  ExtracurricularActivities ParentalSupport  FinalGrade  \\\n",
       "0           78.0                        1.0            High        80.0   \n",
       "1           85.0                        2.0          Medium        87.0   \n",
       "2           65.0                        0.0             Low        68.0   \n",
       "3           90.0                        3.0            High        92.0   \n",
       "4           82.0                        2.0          Medium        85.0   \n",
       "\n",
       "   Study Hours  Attendance (%) Online Classes Taken  \n",
       "0          4.8            59.0                False  \n",
       "1          2.2            70.0                 True  \n",
       "2          4.6            92.0                False  \n",
       "3          2.9            96.0                False  \n",
       "4          4.1            97.0                 True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e7662c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentID                    40\n",
       "Name                         34\n",
       "Gender                       48\n",
       "AttendanceRate               40\n",
       "StudyHoursPerWeek            50\n",
       "PreviousGrade                33\n",
       "ExtracurricularActivities    43\n",
       "ParentalSupport              22\n",
       "FinalGrade                   40\n",
       "Study Hours                  24\n",
       "Attendance (%)               41\n",
       "Online Classes Taken         25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5f5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "\n",
    "# Create binary target: Pass (1) if FinalGrade >= 70, else Fail (0)\n",
    "df_clean = df.dropna(subset=['FinalGrade'])\n",
    "df_clean['Pass'] = (df_clean['FinalGrade'] >= 70).astype(int)\n",
    "\n",
    "# Select features\n",
    "feature_cols = ['AttendanceRate', 'StudyHoursPerWeek', 'PreviousGrade', \n",
    "                'ExtracurricularActivities', 'Study Hours', 'Attendance (%)']\n",
    "\n",
    "# Clean data\n",
    "df_clean = df_clean.dropna(subset=feature_cols)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[feature_cols].values\n",
    "y = df_clean['Pass'].values\n",
    "\n",
    "# Add Gender encoding\n",
    "if 'Gender' in df_clean.columns:\n",
    "    le = LabelEncoder()\n",
    "    gender_encoded = le.fit_transform(df_clean['Gender'].fillna('Unknown'))\n",
    "    X = np.column_stack([X, gender_encoded])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a317718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (767, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f165aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: (767,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbef3667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "  Pass (1): 615 samples (80.18%)\n",
      "  Fail (0): 152 samples (19.82%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class Distribution:\")\n",
    "print(f\"  Pass (1): {sum(y)} samples ({sum(y)/len(y)*100:.2f}%)\")\n",
    "print(f\"  Fail (0): {len(y)-sum(y)} samples ({(len(y)-sum(y))/len(y)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e23da",
   "metadata": {},
   "source": [
    "### 1. Simple Train-Test Split\n",
    "\n",
    "**What it does:** Randomly divides data into training and testing sets.\n",
    "\n",
    "**When to use:**\n",
    "- Quick model evaluation\n",
    "- Large datasets\n",
    "- Initial prototyping\n",
    "\n",
    "**Parameters:**\n",
    "- `test_size`: Proportion of dataset for testing (e.g., 0.2 = 20%)\n",
    "- `random_state`: Seed for reproducibility\n",
    "- `stratify`: Maintains class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c84041c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed6e53c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "\n",
      "Training set:\n",
      "  Size: 613 samples (79.9%)\n",
      "  Pass: 492 (80.3%)\n",
      "  Fail: 121 (19.7%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"  Size: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Pass: {sum(y_train)} ({sum(y_train)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Fail: {len(y_train)-sum(y_train)} ({(len(y_train)-sum(y_train))/len(y_train)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17711a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing set:\n",
      "  Size: 154 samples (20.1%)\n",
      "  Pass: 123 (79.9%)\n",
      "  Fail: 31 (20.1%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTesting set:\")\n",
    "print(f\"  Size: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Pass: {sum(y_test)} ({sum(y_test)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  Fail: {len(y_test)-sum(y_test)} ({(len(y_test)-sum(y_test))/len(y_test)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afc99a",
   "metadata": {},
   "source": [
    "### 2. Train-Validation-Test Split (3-Way Split)\n",
    "\n",
    "**What it does:** Divides data into THREE sets:\n",
    "- **Training:** To train the model\n",
    "- **Validation:** To tune hyperparameters\n",
    "- **Test:** For final evaluation\n",
    "\n",
    "**When to use:**\n",
    "- Hyperparameter tuning\n",
    "- Model selection\n",
    "- When you need unbiased final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3e32ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: separate test set (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2a0eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: separate train and validation (60-20)\n",
    "# From remaining 80%, we want 60% train and 20% validation\n",
    "# So validation is 20/80 = 0.25 of the temp set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd843b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "\n",
      "Training set:   459 samples (59.8%)\n",
      "Validation set: 154 samples (20.1%)\n",
      "Testing set:    154 samples (20.1%)\n",
      "\n",
      "Verification: 459 + 154 + 154 = 767 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"\\nTraining set:   {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set:    {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nVerification: {len(X_train)} + {len(X_val)} + {len(X_test)} = {len(X_train) + len(X_val) + len(X_test)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf56d75",
   "metadata": {},
   "source": [
    "## 3. Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c84ad",
   "metadata": {},
   "source": [
    "### 3.1 K-Fold Cross-Validation\n",
    "\n",
    "**What it does:** Divides data into K equal folds, trains on K-1 folds, tests on 1 fold, repeats K times.\n",
    "\n",
    "**When to use:**\n",
    "- Standard evaluation method\n",
    "- Medium to large datasets\n",
    "- Need robust performance estimate\n",
    "\n",
    "**Common K values:**\n",
    "- K=3: Quick evaluation\n",
    "- K=5: Standard choice\n",
    "- K=10: Thorough evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1a20666",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4da5539c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "Number of folds: 5\n",
      "\n",
      "Split details:\n",
      "\n",
      "  Fold 1:\n",
      "    Training: 613 samples (indices 0-766)\n",
      "    Testing:  154 samples (indices 2-763)\n",
      "    Test Pass Rate: 83.8%\n",
      "\n",
      "  Fold 2:\n",
      "    Training: 613 samples (indices 0-766)\n",
      "    Testing:  154 samples (indices 6-759)\n",
      "    Test Pass Rate: 83.1%\n",
      "\n",
      "  Fold 3:\n",
      "    Training: 614 samples (indices 1-764)\n",
      "    Testing:  153 samples (indices 0-766)\n",
      "    Test Pass Rate: 83.0%\n",
      "\n",
      "  Fold 4:\n",
      "    Training: 614 samples (indices 0-766)\n",
      "    Testing:  153 samples (indices 3-752)\n",
      "    Test Pass Rate: 74.5%\n",
      "\n",
      "  Fold 5:\n",
      "    Training: 614 samples (indices 0-766)\n",
      "    Testing:  153 samples (indices 1-764)\n",
      "    Test Pass Rate: 76.5%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Number of folds: 5\")\n",
    "print(f\"\\nSplit details:\")\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kfold.split(X), 1):\n",
    "    print(f\"\\n  Fold {fold_idx}:\")\n",
    "    print(f\"    Training: {len(train_idx)} samples (indices {train_idx[0]}-{train_idx[-1]})\")\n",
    "    print(f\"    Testing:  {len(test_idx)} samples (indices {test_idx[0]}-{test_idx[-1]})\")\n",
    "    print(f\"    Test Pass Rate: {y[test_idx].mean()*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04c683",
   "metadata": {},
   "source": [
    "### 3.2 Stratified K-Fold Cross-Validation\n",
    "\n",
    "**What it does:** K-Fold that preserves the class distribution in each fold.\n",
    "\n",
    "**When to use:**\n",
    "- **Imbalanced datasets** (IMPORTANT!)\n",
    "- Classification problems\n",
    "- When class distribution matters\n",
    "\n",
    "**Why it matters:** Our dataset has 80% pass rate. Regular K-Fold might create folds with 70% or 90% pass rate. Stratified K-Fold maintains ~80% in ALL folds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4e7180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c2e5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "Number of folds: 5\n",
      "\n",
      "Split details (notice consistent pass rates):\n",
      "\n",
      "  Fold 1:\n",
      "    Training: 613 samples, Pass Rate: 80.3%\n",
      "    Testing:  154 samples, Pass Rate: 79.9%\n",
      "\n",
      "  Fold 2:\n",
      "    Training: 613 samples, Pass Rate: 80.3%\n",
      "    Testing:  154 samples, Pass Rate: 79.9%\n",
      "\n",
      "  Fold 3:\n",
      "    Training: 614 samples, Pass Rate: 80.1%\n",
      "    Testing:  153 samples, Pass Rate: 80.4%\n",
      "\n",
      "  Fold 4:\n",
      "    Training: 614 samples, Pass Rate: 80.1%\n",
      "    Testing:  153 samples, Pass Rate: 80.4%\n",
      "\n",
      "  Fold 5:\n",
      "    Training: 614 samples, Pass Rate: 80.1%\n",
      "    Testing:  153 samples, Pass Rate: 80.4%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Number of folds: 5\")\n",
    "print(f\"\\nSplit details (notice consistent pass rates):\")\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(stratified_kfold.split(X, y), 1):\n",
    "    train_pass_rate = y[train_idx].mean() * 100\n",
    "    test_pass_rate = y[test_idx].mean() * 100\n",
    "    \n",
    "    print(f\"\\n  Fold {fold_idx}:\")\n",
    "    print(f\"    Training: {len(train_idx)} samples, Pass Rate: {train_pass_rate:.1f}%\")\n",
    "    print(f\"    Testing:  {len(test_idx)} samples, Pass Rate: {test_pass_rate:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe061a1e",
   "metadata": {},
   "source": [
    "### 3.3 Repeated K-Fold Cross-Validation\n",
    "\n",
    "**What it does:** Repeats K-Fold CV multiple times with different random splits.\n",
    "\n",
    "**When to use:**\n",
    "- Need very robust evaluation\n",
    "- Critical applications\n",
    "- Reduce impact of random variations\n",
    "\n",
    "**Computational cost:** K Ã— n_repeats (e.g., 5 folds Ã— 3 repeats = 15 iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b00c4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 5-Fold with 3 Repeats\n",
    "\n",
    "n_splits = 5\n",
    "n_repeats = 3\n",
    "\n",
    "repeated_kfold = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7411815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "Number of folds per repeat: 5\n",
      "Number of repeats: 3\n",
      "Total iterations: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Number of folds per repeat: {n_splits}\")\n",
    "print(f\"Number of repeats: {n_repeats}\")\n",
    "print(f\"Total iterations: {n_splits * n_repeats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85761346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Repeat 1:\n",
      "  ----------------------------------------------------------------------\n",
      "    Iteration  1 (Fold 1): Train=613 samples, Test=154 samples\n",
      "    Iteration  2 (Fold 2): Train=613 samples, Test=154 samples\n",
      "    Iteration  3 (Fold 3): Train=614 samples, Test=153 samples\n",
      "    Iteration  4 (Fold 4): Train=614 samples, Test=153 samples\n",
      "    Iteration  5 (Fold 5): Train=614 samples, Test=153 samples\n",
      "\n",
      "  Repeat 2:\n",
      "  ----------------------------------------------------------------------\n",
      "    Iteration  6 (Fold 1): Train=613 samples, Test=154 samples\n",
      "    Iteration  7 (Fold 2): Train=613 samples, Test=154 samples\n",
      "    Iteration  8 (Fold 3): Train=614 samples, Test=153 samples\n",
      "    Iteration  9 (Fold 4): Train=614 samples, Test=153 samples\n",
      "    Iteration 10 (Fold 5): Train=614 samples, Test=153 samples\n",
      "\n",
      "  Repeat 3:\n",
      "  ----------------------------------------------------------------------\n",
      "    Iteration 11 (Fold 1): Train=613 samples, Test=154 samples\n",
      "    Iteration 12 (Fold 2): Train=613 samples, Test=154 samples\n",
      "    Iteration 13 (Fold 3): Train=614 samples, Test=153 samples\n",
      "    Iteration 14 (Fold 4): Train=614 samples, Test=153 samples\n",
      "    Iteration 15 (Fold 5): Train=614 samples, Test=153 samples\n"
     ]
    }
   ],
   "source": [
    "iteration = 1\n",
    "for repeat in range(n_repeats):\n",
    "    print(f\"\\n  Repeat {repeat + 1}:\")\n",
    "    print(f\"  {'-' * 70}\")\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        train_idx, test_idx = list(repeated_kfold.split(X))[iteration - 1]\n",
    "        print(f\"    Iteration {iteration:2d} (Fold {fold + 1}): \"\n",
    "              f\"Train={len(train_idx):3d} samples, Test={len(test_idx):3d} samples\")\n",
    "        iteration += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34023bab",
   "metadata": {},
   "source": [
    "### 3.4 Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    "**What it does:** Uses each sample as a test set once. For n samples, performs n iterations!\n",
    "\n",
    "**When to use:**\n",
    "- **Very small datasets** (<100 samples)\n",
    "- Maximum data utilization needed\n",
    "- Deterministic results required\n",
    "\n",
    "**WARNING:** Extremely expensive! Our full dataset (767 samples) would need 767 iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "890b44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration on a small subset\n",
    "subset_size = 20\n",
    "X_subset = X[:subset_size]\n",
    "y_subset = y[:subset_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae0ee6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "n_splits_loo = loo.get_n_splits(X_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62202ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subset size: 20 samples\n",
      "Number of iterations: 20\n",
      "Training size per iteration: 19 samples\n",
      "Test size per iteration: 1 sample\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSubset size: {subset_size} samples\")\n",
    "print(f\"Number of iterations: {n_splits_loo}\")\n",
    "print(f\"Training size per iteration: {subset_size - 1} samples\")\n",
    "print(f\"Test size per iteration: 1 sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3191472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 iterations:\n",
      "  Iteration  1: Train on 19 samples, Test on sample #0 (class=1)\n",
      "  Iteration  2: Train on 19 samples, Test on sample #1 (class=1)\n",
      "  Iteration  3: Train on 19 samples, Test on sample #2 (class=0)\n",
      "  Iteration  4: Train on 19 samples, Test on sample #3 (class=1)\n",
      "  Iteration  5: Train on 19 samples, Test on sample #4 (class=0)\n",
      "  Iteration  6: Train on 19 samples, Test on sample #5 (class=1)\n",
      "  Iteration  7: Train on 19 samples, Test on sample #6 (class=1)\n",
      "  Iteration  8: Train on 19 samples, Test on sample #7 (class=1)\n",
      "  Iteration  9: Train on 19 samples, Test on sample #8 (class=0)\n",
      "  Iteration 10: Train on 19 samples, Test on sample #9 (class=1)\n",
      "  ... (10 more iterations)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFirst 10 iterations:\")\n",
    "for iteration, (train_idx, test_idx) in enumerate(loo.split(X_subset), 1):\n",
    "    if iteration <= 10:\n",
    "        print(f\"  Iteration {iteration:2d}: Train on {len(train_idx)} samples, \"\n",
    "              f\"Test on sample #{test_idx[0]} (class={y_subset[test_idx[0]]})\")\n",
    "    if iteration == 10:\n",
    "        print(f\"  ... ({subset_size - 10} more iterations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bdaa9",
   "metadata": {},
   "source": [
    "### 3.5 Shuffle Split Cross-Validation\n",
    "\n",
    "**What it does:** Creates random independent train/test splits.\n",
    "\n",
    "**When to use:**\n",
    "- Need custom train/test sizes\n",
    "- Want specific number of iterations\n",
    "- Flexible evaluation needed\n",
    "\n",
    "**Difference from K-Fold:** Splits are independent - samples may appear in multiple test sets or never!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e46c285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_split = ShuffleSplit(n_splits=10, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cab6b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "Number of splits: 10\n",
      "Test size: 30%\n",
      "\n",
      "Split details:\n",
      "  Split  1: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  2: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  3: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  4: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  5: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  6: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  7: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  8: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split  9: Train=536 samples (69.9%), Test=231 samples (30.1%)\n",
      "  Split 10: Train=536 samples (69.9%), Test=231 samples (30.1%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Number of splits: 10\")\n",
    "print(f\"Test size: 30%\")\n",
    "print(f\"\\nSplit details:\")\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(shuffle_split.split(X), 1):\n",
    "    print(f\"  Split {split_idx:2d}: Train={len(train_idx):3d} samples ({len(train_idx)/len(X)*100:.1f}%), \"\n",
    "          f\"Test={len(test_idx):3d} samples ({len(test_idx)/len(X)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5511073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "Number of splits: 5\n",
      "Test size: 20%\n",
      "\n",
      "Split details:\n"
     ]
    }
   ],
   "source": [
    "shuffle_split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Number of splits: 5\")\n",
    "print(f\"Test size: 20%\")\n",
    "print(f\"\\nSplit details:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a1d2485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split 1: Train=613 samples, Test=154 samples\n",
      "  Split 2: Train=613 samples, Test=154 samples\n",
      "  Split 3: Train=613 samples, Test=154 samples\n",
      "  Split 4: Train=613 samples, Test=154 samples\n",
      "  Split 5: Train=613 samples, Test=154 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(shuffle_split.split(X), 1):\n",
    "    print(f\"  Split {split_idx}: Train={len(train_idx)} samples, Test={len(test_idx)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01c61a",
   "metadata": {},
   "source": [
    "## 4. Specialized techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b78cf",
   "metadata": {},
   "source": [
    "### 4.1 Time Series Split\n",
    "\n",
    "**What it does:** Respects temporal order - always trains on PAST data, tests on FUTURE data.\n",
    "\n",
    "**When to use:**\n",
    "- **Time series forecasting** (CRITICAL!)\n",
    "- Any temporal data\n",
    "- When order matters\n",
    "\n",
    "**CRITICAL:** Never use regular K-Fold on time series - it will train on future data (data leakage)!\n",
    "\n",
    "**How it works:** Training set grows with each split:\n",
    "```\n",
    "Split 1: Train[0:100] â†’ Test[100:200]\n",
    "Split 2: Train[0:200] â†’ Test[200:300]\n",
    "Split 3: Train[0:300] â†’ Test[300:400]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6006aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-ordered data\n",
    "X_time = X.copy()\n",
    "y_time = y.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "743a4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a818d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 767\n",
      "Number of splits: 5\n",
      "\n",
      "Split details (notice growing training set):\n",
      "\n",
      "  Split 1:\n",
      "    Training: samples 0 to 131 (132 total)\n",
      "    Testing:  samples 132 to 258 (127 total)\n",
      "    Time order: Train on PAST [0-131], Test on FUTURE [132-258]\n",
      "\n",
      "  Split 2:\n",
      "    Training: samples 0 to 258 (259 total)\n",
      "    Testing:  samples 259 to 385 (127 total)\n",
      "    Time order: Train on PAST [0-258], Test on FUTURE [259-385]\n",
      "\n",
      "  Split 3:\n",
      "    Training: samples 0 to 385 (386 total)\n",
      "    Testing:  samples 386 to 512 (127 total)\n",
      "    Time order: Train on PAST [0-385], Test on FUTURE [386-512]\n",
      "\n",
      "  Split 4:\n",
      "    Training: samples 0 to 512 (513 total)\n",
      "    Testing:  samples 513 to 639 (127 total)\n",
      "    Time order: Train on PAST [0-512], Test on FUTURE [513-639]\n",
      "\n",
      "  Split 5:\n",
      "    Training: samples 0 to 639 (640 total)\n",
      "    Testing:  samples 640 to 766 (127 total)\n",
      "    Time order: Train on PAST [0-639], Test on FUTURE [640-766]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(X_time)}\")\n",
    "print(f\"Number of splits: 5\")\n",
    "print(f\"\\nSplit details (notice growing training set):\")\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(tscv.split(X_time), 1):\n",
    "    print(f\"\\n  Split {split_idx}:\")\n",
    "    print(f\"    Training: samples 0 to {len(train_idx)-1} ({len(train_idx)} total)\")\n",
    "    print(f\"    Testing:  samples {len(train_idx)} to {len(train_idx)+len(test_idx)-1} ({len(test_idx)} total)\")\n",
    "    print(f\"    Time order: Train on PAST [{train_idx[0]}-{train_idx[-1]}], \"\n",
    "          f\"Test on FUTURE [{test_idx[0]}-{test_idx[-1]}]\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f3c6d",
   "metadata": {},
   "source": [
    "### 4.2 Group K-Fold Cross-Validation\n",
    "\n",
    "**What it does:** Keeps all samples from the same group together in the same fold.\n",
    "\n",
    "**When to use:**\n",
    "- Medical data (multiple samples from same patient)\n",
    "- User behavior (multiple actions from same user)\n",
    "- School data (multiple students from same school)\n",
    "- **Prevent group-level leakage**\n",
    "\n",
    "**Example problem:** If Patient A has 5 blood tests, you don't want 3 tests in training and 2 in testing - that leaks information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "947d8017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info:\n",
      "  Total samples: 767\n",
      "  Number of groups: 4\n",
      "\n",
      "Samples per group:\n",
      "  Group 0: 221 samples\n",
      "  Group 1: 223 samples\n",
      "  Group 2: 177 samples\n",
      "  Group 3: 146 samples\n"
     ]
    }
   ],
   "source": [
    "# Create groups (simulating students from different schools/groups)\n",
    "# Using attendance rate quartiles as proxy for groups\n",
    "groups = pd.qcut(df_clean['AttendanceRate'].values, q=4, labels=False, duplicates='drop')\n",
    "\n",
    "print(f\"\\nDataset info:\")\n",
    "print(f\"  Total samples: {len(X)}\")\n",
    "print(f\"  Number of groups: {len(np.unique(groups))}\")\n",
    "print(f\"\\nSamples per group:\")\n",
    "for group_id in np.unique(groups):\n",
    "    count = np.sum(groups == group_id)\n",
    "    print(f\"  Group {group_id}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96325cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of folds: 4\n",
      "\n",
      "Split details:\n",
      "\n",
      "  Fold 1:\n",
      "    Training: 544 samples from groups [0, 2, 3]\n",
      "    Testing:  223 samples from groups [1]\n",
      "    âœ“ No overlap in groups between train and test!\n",
      "\n",
      "  Fold 2:\n",
      "    Training: 546 samples from groups [1, 2, 3]\n",
      "    Testing:  221 samples from groups [0]\n",
      "    âœ“ No overlap in groups between train and test!\n",
      "\n",
      "  Fold 3:\n",
      "    Training: 590 samples from groups [0, 1, 3]\n",
      "    Testing:  177 samples from groups [2]\n",
      "    âœ“ No overlap in groups between train and test!\n",
      "\n",
      "  Fold 4:\n",
      "    Training: 621 samples from groups [0, 1, 2]\n",
      "    Testing:  146 samples from groups [3]\n",
      "    âœ“ No overlap in groups between train and test!\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=4)\n",
    "\n",
    "print(f\"\\nNumber of folds: 4\")\n",
    "print(f\"\\nSplit details:\")\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(group_kfold.split(X, y, groups), 1):\n",
    "    train_groups = np.unique(groups[train_idx])\n",
    "    test_groups = np.unique(groups[test_idx])\n",
    "    \n",
    "    print(f\"\\n  Fold {fold_idx}:\")\n",
    "    print(f\"    Training: {len(train_idx)} samples from groups {list(train_groups)}\")\n",
    "    print(f\"    Testing:  {len(test_idx)} samples from groups {list(test_groups)}\")\n",
    "    print(f\"    âœ“ No overlap in groups between train and test!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810892d1",
   "metadata": {},
   "source": [
    "### 4.3 Stratified Group K-Fold\n",
    "\n",
    "**What it does:** Combines stratification (class balance) with group separation.\n",
    "\n",
    "**When to use:**\n",
    "- Grouped data + Imbalanced classes\n",
    "- Medical studies with patient groups\n",
    "- Best of both worlds needed\n",
    "\n",
    "**Example:** Hospital study with patients from different locations, and rare disease (imbalanced classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "680fd78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of folds: 4\n",
      "\n",
      "Split details (maintaining both group integrity AND class balance):\n",
      "\n",
      "  Fold 1:\n",
      "    Training: 590 samples from groups [0, 1, 3]\n",
      "              Pass Rate: 79.7%\n",
      "    Testing:  177 samples from groups [2]\n",
      "              Pass Rate: 81.9%\n",
      "    âœ“ Groups separated AND class balance maintained!\n",
      "\n",
      "  Fold 2:\n",
      "    Training: 546 samples from groups [1, 2, 3]\n",
      "              Pass Rate: 80.2%\n",
      "    Testing:  221 samples from groups [0]\n",
      "              Pass Rate: 80.1%\n",
      "    âœ“ Groups separated AND class balance maintained!\n",
      "\n",
      "  Fold 3:\n",
      "    Training: 621 samples from groups [0, 1, 2]\n",
      "              Pass Rate: 80.0%\n",
      "    Testing:  146 samples from groups [3]\n",
      "              Pass Rate: 80.8%\n",
      "    âœ“ Groups separated AND class balance maintained!\n",
      "\n",
      "  Fold 4:\n",
      "    Training: 544 samples from groups [0, 2, 3]\n",
      "              Pass Rate: 80.9%\n",
      "    Testing:  223 samples from groups [1]\n",
      "              Pass Rate: 78.5%\n",
      "    âœ“ Groups separated AND class balance maintained!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stratified_group_kfold = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nNumber of folds: 4\")\n",
    "print(f\"\\nSplit details (maintaining both group integrity AND class balance):\")\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(stratified_group_kfold.split(X, y, groups), 1):\n",
    "    train_groups = np.unique(groups[train_idx])\n",
    "    test_groups = np.unique(groups[test_idx])\n",
    "    train_pass_rate = y[train_idx].mean() * 100\n",
    "    test_pass_rate = y[test_idx].mean() * 100\n",
    "    \n",
    "    print(f\"\\n  Fold {fold_idx}:\")\n",
    "    print(f\"    Training: {len(train_idx)} samples from groups {list(train_groups)}\")\n",
    "    print(f\"              Pass Rate: {train_pass_rate:.1f}%\")\n",
    "    print(f\"    Testing:  {len(test_idx)} samples from groups {list(test_groups)}\")\n",
    "    print(f\"              Pass Rate: {test_pass_rate:.1f}%\")\n",
    "    print(f\"    âœ“ Groups separated AND class balance maintained!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2e330",
   "metadata": {},
   "source": [
    "## 5. Advanced Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e521e4b",
   "metadata": {},
   "source": [
    "### 5.1 Stratified Shuffle Split\n",
    "\n",
    "**What it does:** Combines Shuffle Split flexibility with stratification.\n",
    "\n",
    "**When to use:**\n",
    "- Imbalanced data + custom split sizes\n",
    "- Need multiple random evaluations\n",
    "- Want both stratification and flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcd96c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stratified_shuffle = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9d0e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 767\n",
      "Number of splits: 10\n",
      "Test size: 25%\n",
      "\n",
      "Split details (notice consistent pass rates):\n",
      "  Split  1: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  2: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  3: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  4: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  5: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  6: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  7: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  8: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split  9: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n",
      "  Split 10: Train=575 samples (Pass: 80.2%), Test=192 samples (Pass: 80.2%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal samples: {len(X)}\")\n",
    "print(f\"Number of splits: 10\")\n",
    "print(f\"Test size: 25%\")\n",
    "print(f\"\\nSplit details (notice consistent pass rates):\")\n",
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(stratified_shuffle.split(X, y), 1):\n",
    "    train_pass_rate = y[train_idx].mean() * 100\n",
    "    test_pass_rate = y[test_idx].mean() * 100\n",
    "    \n",
    "    print(f\"  Split {split_idx:2d}: Train={len(train_idx)} samples (Pass: {train_pass_rate:.1f}%), \"\n",
    "          f\"Test={len(test_idx)} samples (Pass: {test_pass_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430d26b",
   "metadata": {},
   "source": [
    "### 5.2 Predefined Split\n",
    "\n",
    "**What it does:** Uses pre-assigned train/test split indicators.\n",
    "\n",
    "**When to use:**\n",
    "- Splits determined by business rules\n",
    "- Specific organizational requirements\n",
    "- Time-based splits (before/after date)\n",
    "- Custom stratification needed\n",
    "\n",
    "**Example use cases:**\n",
    "- Train on 2023 data, test on 2024 data\n",
    "- Train on Site A, test on Site B\n",
    "- Custom business logic for splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b359d30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Example: Predefined Split Based on Attendance Rate\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Split Criteria: Students with >90% attendance â†’ Test Set\n",
      "                Students with â‰¤90% attendance â†’ Training Set\n",
      "\n",
      "Total samples: 767\n"
     ]
    }
   ],
   "source": [
    "# Create predefined split based on attendance rate\n",
    "# High attendance (>90) goes to test, rest goes to train\n",
    "test_fold = np.where(df_clean['AttendanceRate'].values > 90, 0, -1)\n",
    "\n",
    "print(\"\\nðŸ“ Example: Predefined Split Based on Attendance Rate\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nSplit Criteria: Students with >90% attendance â†’ Test Set\")\n",
    "print(\"                Students with â‰¤90% attendance â†’ Training Set\")\n",
    "\n",
    "predefined_split = PredefinedSplit(test_fold)\n",
    "\n",
    "print(f\"\\nTotal samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39b7f526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split 1:\n",
      "  Training Set:\n",
      "    Size: 525 samples (68.4%)\n",
      "    Average Attendance: 82.4%\n",
      "    Pass Rate: 80.4%\n",
      "\n",
      "  Testing Set:\n",
      "    Size: 242 samples (31.6%)\n",
      "    Average Attendance: 92.7%\n",
      "    Pass Rate: 79.8%\n",
      "\n",
      "Split Assignment Details:\n",
      "  Training samples (fold = -1): 525\n",
      "  Testing samples (fold = 0):   242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for split_idx, (train_idx, test_idx) in enumerate(predefined_split.split(), 1):\n",
    "    train_attendance = df_clean['AttendanceRate'].iloc[train_idx].mean()\n",
    "    test_attendance = df_clean['AttendanceRate'].iloc[test_idx].mean()\n",
    "    \n",
    "    print(f\"\\nSplit {split_idx}:\")\n",
    "    print(f\"  Training Set:\")\n",
    "    print(f\"    Size: {len(train_idx)} samples ({len(train_idx)/len(X)*100:.1f}%)\")\n",
    "    print(f\"    Average Attendance: {train_attendance:.1f}%\")\n",
    "    print(f\"    Pass Rate: {y[train_idx].mean()*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n  Testing Set:\")\n",
    "    print(f\"    Size: {len(test_idx)} samples ({len(test_idx)/len(X)*100:.1f}%)\")\n",
    "    print(f\"    Average Attendance: {test_attendance:.1f}%\")\n",
    "    print(f\"    Pass Rate: {y[test_idx].mean()*100:.1f}%\")\n",
    "\n",
    "# Show split assignment\n",
    "print(f\"\\nSplit Assignment Details:\")\n",
    "print(f\"  Training samples (fold = -1): {np.sum(test_fold == -1)}\")\n",
    "print(f\"  Testing samples (fold = 0):   {np.sum(test_fold == 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7f99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
